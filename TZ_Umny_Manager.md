## Техническое задание: «Умный менеджер» (Answer-First)

### 0. Контекст проекта
- Текущая кодовая база: `sell/app` (aiogram v3 + FastAPI backend).
- Нельзя нарушать актуальные сценарии и функции. Новая логика должна быть надстройкой поверх существующих сервисов (`llm_service`, `scheduler_service`, `prompt_loader`, `handlers/*`).
- Цель — повысить качество диалогов и конверсию за счёт ответов «как умный менеджер» при сохранении сценарной воронки.

### 1. Цель и результат
- В каждый диалог встроено правило **Answer-First**: бот сначала отвечает на намерение пользователя, затем мягко возвращается к целевому сценарию.
- Диалог управляет трёхслойная архитектура: Intent Router → Skill → Stage FSM.
- LLM всегда выдаёт структурированный JSON (answer, next_action, stage_transition, buttons, confidence, safety_flags).
- Ответы опираются на проверяемые данные (FAQ, продукты, процессы); при неизвестных фактах — честное признание и предложение эскалации.
- Встроена обработка критичных намерений (оплата, запись, поддержка), токсичности, повторных низких увереннностей.
- Бот удерживает краткую память диалога (цель, барьеры, обещания) и закрывает «открытые петли».
- Метрики качества позволяют отслеживать выполнение политики Answer-First и влияние на воронку.

### 2. Приоритеты внедрения
- **P0 (критично для запуска Answer-First)**: системный промпт, Intent Router, Skill Layer (базовые скиллы), обновление FSM, структурированный ответ LLM, fact-base, счётчик низкой уверенности и эскалация.
- **P1 (улучшение эффективности)**: расширенные возражения, память диалога, метрики/дашборд, unit-тесты на навыки и маршрутизацию.
- **P2 (следующие итерации)**: ML-классификатор намерений, персонализация CTA, A/B-тесты, автообучение.
- Очерёдность задач для MVP: Intent Router → Skills → JSON-ответ LLM → Grounding → FSM pause/return → Confidence tracking → Memory → Метрики.

### 3. Принцип Answer-First (верхнеуровневое требование)
- Жёсткое правило в system-промпте: «Сначала ответь по сути на вопрос/намерение пользователя, затем мягко продолжай воронку».
- Приёмка: в ≥ 90% проверок (ручные тесты 30+ кейсов) бот сначала даёт релевантный ответ, затем CTA/следующий шаг сценария.
- Обязательные проверки:
  - Вопрос о цене/условиях на этапе анкеты → бот даёт цену и только потом напоминает про следующий шаг.
  - Просьба записать/оплатить в любой точке → выполняется действие вне зависимости от этапа.

### 4. Архитектура решения (три слоя)

#### 4.1 Intent Router
- Назначение: классифицировать входящие сообщения по списку намерений.
- Категории (расширяемый enum): `faq`, `price`, `objection`, `book_consult`, `pay`, `support`, `escalation`, `small_talk`, `offtopic`, `toxic`, `chit_chat`, `decline`, `other`.
- Доп. атрибуты:
  - `urgency`: `low | medium | high` (высокая — оплата/поддержка/агрессия).
  - `sentiment`: `positive | neutral | negative`.
- Реализация на первом этапе: словари ключевых слов + simple heuristics + счётчик негативных триггеров из `SafetyValidator`.
- Интерфейс: синхронный/асинхронный сервис `IntentRouter.classify(message, context) -> IntentResult`.
- Логгирование: записывать исходный текст, выявленное намерение, уверенность в таблицу/лог для последующей ML-замены.

#### 4.2 Skill Layer
- Каждый `Skill` реализует контракт:
  ```python
  class SkillProtocol(Protocol):
      intent: IntentType
      async def handle(self, state: DialogueState, llm_response: LLMRawMessage) -> SkillResult: ...
  ```
- Обязательные скиллы:
  - FAQ/Knowledge answer (использует grounding данные).
  - Present Product (персонализация по сегменту/ответам).
  - Book Consultation (поддержка текущих сценариев записи + свободный ввод).
  - Send Payment (формирует ссылку/инструкцию из факт-таблицы).
  - Objection Handling (подключение библиотеки реплик).
  - Support/Troubleshooting (отдельная факт-линия, CTA «передать менеджеру»).
  - Escalate to Manager (создание карточки, уведомление).
- Каждому скиллу доступен список разрешённых действий + шаблонов ответов.
- Скиллы не ломают FSM: после завершения сообщают `stage_transition`.

#### 4.3 Stage FSM (оркестратор воронки)
- Отслеживает текущую стадию (`lead_generation`, `qualification`, `education`, `conversion`, `post_conversion`).
- Методы:
  - `apply_skill_result(skill_result)` — обновляет стадию или ставит на паузу.
  - `suggest_next_step()` — возвращает сценарный шаг для мягкого продолжения (используется LLM или handler).
- FSM принимает `stage_transition`: `stay`, `next:<stage_id>`, `pause`.
- В состоянии `pause` держит «открытую сцену» и возобновляет после ответа на намерение.
- Интеграция с существующими handlers: FSM-хранилище в Redis/БД или runtime state (минимально — расширение `UserContext`).

#### 4.4 Поток данных
1. Сообщение пользователя → Intent Router → IntentResult.
2. Skill Manager выбирает скилл (по IntentResult, Stage).
3. Скилл подготавливает инструкцию для LLM (grounding + запреты) и вызывает `LLMService`.
4. LLM формирует ответ (структура ниже).
5. Полиси-слой (`PolicyLayer`) дополняет: проверка повтора, эскалации, Answer-First.
6. FSM обновляет стадию, UI-кнопки → отправляется пользователю.

### 5. Формат ответа LLM (строгий JSON)
- Структура:
  ```json
  {
    "answer": "<краткий человеческий ответ>",
    "next_action": "<atomic_action_id>",
    "stage_transition": "stay | pause | next:<stage_id>",
    "buttons": [{"id": "consult_book", "text": "Записаться на консультацию"}],
    "confidence": 0.0-1.0,
    "safety_flags": ["no_guarantees", "sensitive_topic"]
  }
  ```
- В `messages_history` хранить JSON-ответы (в meta), чтобы PolicyLayer мог анализировать.
- Обновление `prompt_loader`: новый системный файл `prompts/system_answer_first.txt` с инструкцией по формату и Answer-First.
- Парсинг в `LLMService`:
  - Жёсткий JSON parse с валидацией схемы (`pydantic` модель).
  - Если парсинг падает → fallback-ответ, лог, эскалация.

### 6. Grounding (источники истины)
- Создать каталог `app/knowledge` с данными:
  - `faq.yml` — вопрос/ответ + теги + «нельзя обещать».
  - `products.yml` — название, кому подходит, ценность, цена, ограничения, CTA.
  - `processes.yml` — шаги записи, оплаты, отказов, поддержка.
- Логика:
  - Intent Router/Skills подмешивают релевантные факты в `LLMContext`.
  - Если факт не найден → `answer` обязан сообщить «уточню у менеджера», `next_action = escalate`.
- Приёмка: ручной аудит 20 вопросов → ни одного придуманного факта.

### 7. Правила приоритета намерений
- Таблица приоритета (от высокого к низкому):
  1. `pay`, `book_consult`, `support` — прерывают сцену. Скилл должен завершить действие до возврата к сценарию.
  2. `price`, `product_question` — сначала ответ, затем мягкий CTA.
  3. `objection`, `negative` — использовать библиотеку возражений, без давления.
  4. `offtopic`, `small_talk` — вежливо ответить и вернуть к цели одной репликой.
  5. `other` — default поведение (образовательный сценарий).
- Конфликты решаются правилом: «Answer-First + приоритет красных намерений».

### 8. Стиль общения
- Формула ответа (≤ 3–5 предложений):
  1. **ACK** — короткое признание вопроса/эмоции.
  2. **Ответ по сути** (без обещания прибыли).
  3. **CTA/следующий шаг** (один понятный выбор).
- Тон: эмпатичный, уверенный, без споров и обещаний результата.
- Пример: «Понимаю, что цена важна. Полный тариф стоит 49 000 ₽, рассрочка доступна на 3 месяца. Готов записать вас на короткий созвон или выслать программу — что удобнее?»

### 9. Эскалация и низкая уверенность
- В `LLMService` ввести счётчик подряд ответов с `confidence < 0.5`.
- Правило: если два раза подряд < 0.5 или Intent содержит токсичность/агрессию:
  - Answer включает извинение/уточнение.
  - `next_action = escalate_to_manager`.
  - Отправить карточку в канал менеджеров с последними 3 сообщениями и тегом `low_confidence`.
- Лимитировать самоповторы: PolicyLayer запрещает более двух тех же `next_action` подряд.

### 10. Память диалога и «открытые петли»
- Хранилище памяти (в `UserContext` или отдельная таблица): минимум:
  - `user_goal` (1 строка),
  - `barriers` (1 строка),
  - `promises` (список коротких строк).
- Перед вызовом LLM контекст получает эти строки.
- Алгоритм:
  - При каждом ответе обновлять память (skill responsibility).
  - Если есть невыполненные `promises` → добавлять пункт в `buttons` или `answer`, пока не закрыто.
- Приёмка: в тестах бот не повторяет уже закрытые вопросы, выполняет обещания в ответах.

### 11. План задач MVP (итерация 1)
| № | Задача | Приоритет | Результат | Ответственный |
|---|--------|-----------|-----------|---------------|
| 1 | Добавить системный промпт Answer-First + JSON схему | P0 | `prompts/system_answer_first.txt`, обновлённый `LLMService` | Prompt Engineer |
| 2 | Реализовать Intent Router (keywords + sentiment) | P0 | `app/services/intent_router.py`, unit-тесты | Backend Dev 1 |
| 3 | Создать базовые навыки (`Faq`, `Price`, `BookConsult`, `Support`, `Objection`, `Escalation`) | P0 | Пакет `app/services/skills`, интеграция с роутером | Backend Dev 2 |
| 4 | Обновить FSM для `pause/stay/next` и восстановления сцен | P0 | `StageOrchestrator`, хранение стадии в `UserContext` | Backend Dev 1 |
| 5 | Организовать fact-base (`app/knowledge/*.yml`) и загрузчик | P0 | Данные и сервис подмешивания фактов | Backend Dev 2 |
| 6 | Встроить счётчик низкой уверенности + токсичность → эскалация | P0 | Доп. логика в `LLMService`, уведомление менеджеров | Backend Dev 1 |
| 7 | Реализовать память диалога и контроль открытых петель | P1 | Обновления `UserContext`, обновление навыков | Backend Dev 2 |
| 8 | Настроить метрики и логирование (Prometheus, intents) | P1 | Экспортер в `app/main`, интеграция с трекером | DevOps |
| 9 | Подготовить библиотеку возражений и шаблоны CTA | P1 | `app/knowledge/objections.yml`, подключение в `ObjectionSkill` | Content Lead |
| 10 | Написать тесты: unit + сценарные Answer-First | P1 | `tests/intent`, `tests/dialog` | QA |

### 12. Дальнейшая доработка (итерация 2+)
- ML-классификатор намерений (fine-tuning или embeddings).
- Персонализация CTA по сегменту и активности воронки.
- A/B тест Answer-First vs control.
- Расширение навыков (upsell, рассылки, бэкофис).
- Автообучение на диалогах (semi-supervised).

### 13. Интеграция и изменения в коде
- `app/services/intent_router.py` — новый модуль, unit-тесты на классификацию.
- `app/services/skills/…` — пакет для навыков, по одному классу на намерение, c unit-тестами.
- `app/services/fsm/stage_orchestrator.py` — FSM со storage-интерфейсом.
- `app/services/llm_service.py` — обновления:
  - новый системный промпт + JSON валидация (`pydantic`).
  - счётчик низкой уверенности, эскалация.
  - интеграция с IntentResult/SkillResult.
- `app/middlewares/user_context.py` и/или репозитории — хранение памяти и stage.
- Хранилище знаний (`app/knowledge/*.yml`) + загрузчик в `prompt_loader`.
- Новые тесты: unit (`pytest`) + сценарные (Answer-First compliance).

### 14. Метрики качества (дашборд)
- `first_intent_hit` — `answered_intent / total_intent_cases`, цель ≥ 85%.
- `clarification_rate` — доля кейсов, где бот запрашивает 1 уточнение перед решением.
- `escalation_rate` — мониторинг спайков; целевой верхний порог договориться с бизнесом.
- `time_to_resolution` — среднее количество реплик до главного действия (запись/оплата).
- `sentiment_delta` — изменение `lead_level_percent` до/после ответа (использовать счётчик из текущего проекта).
- Метрики писать в Prometheus labels (intent, stage, segment).

### 15. Приёмка и тестирование
- Чек-лист из 30 сценариев (ценовой вопрос, запись, возражение, токсик и т.д.) — ≥ 90% проходят Answer-First.
- 10 сценариев с фактами → 0 придуманной информации.
- 5 сценариев с токсичностью/низкой уверенностью → корректная эскалация.
- Регрессионные тесты текущих функций (`pytest`, интеграционные тесты handlers) — должны оставаться зелёными.
- Демонстрация видео/логов с KPI: первая реплика, эскалации, закрытие обещаний.

### 16. Документация и обучение
- Обновить `README.md` (раздел «Умный менеджер»): краткое описание архитектуры.
- Подготовить шпаргалку для менеджеров (как читать карточки эскалаций, какие лейблы приходят).
- Добавить примеры форматирования JSON-ответов в `prompts/examples/answer_first.json`.

---
Ответственный за реализацию MVP: руководитель разработки Telegram-бота.  
Срок MVP: 2 недели при выделенной команде (2 backend, prompt-engineer, аналитик).  
Статус: документ готов к реализации, задачи сформированы по приоритетам.
